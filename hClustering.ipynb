{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PROCESADO DE DATOS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# VISUALIZACION\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ijson\n",
    "import json\n",
    "import random\n",
    "# UNDER SAMPLING\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter\n",
    "\n",
    "import missingno as msno\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "inline_rc = dict(mpl.rcParams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CARGAMOS LOS DATOS DE yelp_academic_dataset_review.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reviews = []\n",
    "with open('data/yelp_academic_dataset_review.json') as fl:\n",
    "    i=0\n",
    "    for review in fl:\n",
    "        reviews.append(json.loads(review))\n",
    "        i+=1\n",
    "        if i + 1 > 10000:\n",
    "            break\n",
    "\n",
    "df_review = pd.DataFrame(reviews)\n",
    "print(df_review.head())\n",
    "\"\"\"\n",
    "\n",
    "df_review = pd.read_csv('data/yelp_reviews.csv')\n",
    "print(df_review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CARGAMOS LOS DATOS DE yelp_academic_dataset_business.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "business = []\n",
    "with open('data/yelp_academic_dataset_business.json') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        business.append(json.loads(line))\n",
    "\n",
    "df_business = pd.DataFrame(business)\n",
    "print(df_business.head())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "useful_reviews = len(df_review[df_review[\"useful\"]>0])\n",
    "cool_reviews = len(df_review[df_review[\"cool\"]>0])\n",
    "funny_reviews = len(df_review[df_review[\"funny\"]>0])\n",
    "negative_reviws = len(df_review[df_review[\"stars\"]<2])\n",
    "positive_reviews =len(df_review[df_review[\"stars\"]>3])\n",
    "total_reviews = len(df_review)\n",
    "\n",
    "print(\"Total reviews: {}\".format(total_reviews))\n",
    "print(\"Useful reviews: {}\".format(useful_reviews))\n",
    "print(\"Funny reviews: {}\".format(funny_reviews))\n",
    "print(\"Cool reviews: {}\".format(cool_reviews))\n",
    "print(\"Total negative reviews: {}\".format(negative_reviws))\n",
    "print(\"Total positive reviews: {}\".format(positive_reviews))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ELIMINAMOS LAS COLUMNAS INNECESARIAS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_review = df_review.drop([\"review_id\", \"user_id\", \"useful\", \"funny\", \"cool\", \"date\"], axis=1)\n",
    "df_business = df_business.drop([\"name\", \"address\", \"city\", \"state\", \"postal_code\", \"latitude\", \"longitude\", \"stars\", \"review_count\", \"is_open\", \"attributes\", \"hours\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "COMPROBAMOS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_review.head())\n",
    "print(df_business.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "X = []\n",
    "for r in df_review[\"text\"]: #Por cada review\n",
    "    txt = word_tokenize(r.lower()) #Separa la review en palabras\n",
    "    newtxt = \"\"\n",
    "    for w in txt: #Por cada palabra en txt\n",
    "        l = lemma.lemmatize(w) #se hace lo de quitar mayusculas y quitar raice y eso\n",
    "        newtxt += l+\" \"\n",
    "    X.append(newtxt)\n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X= X.toarray()\n",
    "X=pd.DataFrame(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seaborn Plot Styling\n",
    "sns.set(style=\"white\", palette=\"husl\")\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# New imports, specific to this example\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "def mai():\n",
    "  D = 2                     # Dimensionality\n",
    "  s = 4                     # Separation so we can control how far apart the means are\n",
    "  mu1 = np.array([0, 0])\n",
    "  mu2 = np.array([s, s])\n",
    "  mu3 = np.array([0, s])\n",
    "\n",
    "  # Call linkage on X, pass in parameter telling what type of linkage to use\n",
    "  Z = linkage(X, 'ward')\n",
    "  # In general, Z will have format index1, index2 for two index's in X that represent the\n",
    "  # points that are joined at that moment. The third column will be the distance, which is\n",
    "  # how far apart the two clusters were before being joined, and the 4th column will be\n",
    "  # sample count, which is the number of points in that cluster. Hence, the size of Z will\n",
    "  # be ((N - 1) x 4)\n",
    "  print(\"Z shape\", Z.shape)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  plt.title(\"Ward\")\n",
    "  dendrogram(Z)      # Call dendrogram on Z\n",
    "  plt.show()\n",
    "\n",
    "  # Now do single linkage for a different example\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  Z = linkage(X, 'single')\n",
    "  plt.title(\"Single\")\n",
    "  dendrogram(Z)\n",
    "  plt.show()\n",
    "\n",
    "  # And one more for complete\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  Z = linkage(X, 'complete')\n",
    "  plt.title(\"Complete\")\n",
    "  dendrogram(Z)\n",
    "  plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mai()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Distance_computation_grid(object):\n",
    "    '''\n",
    "        class to enable the Computation of distance matrix\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compute_distance(self,samples):\n",
    "        '''\n",
    "            Creates a matrix of distances between individual samples and clusters attained at a particular step\n",
    "        '''\n",
    "        Distance_mat = np.zeros((len(samples),len(samples)))\n",
    "        for i in range(Distance_mat.shape[0]):\n",
    "            for j in range(Distance_mat.shape[0]):\n",
    "                if i!=j:\n",
    "                    Distance_mat[i,j] = float(self.distance_calculate(samples[i],samples[j]))\n",
    "                else:\n",
    "                    Distance_mat[i,j] = 10**4\n",
    "        return Distance_mat\n",
    "\n",
    "\n",
    "    def distance_calculate(self,sample1,sample2):\n",
    "        '''\n",
    "            Distance calulated between two samples. The two samples can be both samples, both clusters or\n",
    "            one cluster and one sample. If both of them are samples/clusters, then simple norm is used. In other\n",
    "            cases, we refer it as an exception case and pass the samples as parameter to some function that\n",
    "            calculates the necessary distance between cluster and a sample\n",
    "        '''\n",
    "        dist = []\n",
    "        for i in range(len(sample1)):\n",
    "            for j in range(len(sample2)):\n",
    "                try:\n",
    "                    dist.append(np.linalg.norm(np.array(sample1[i])-np.array(sample2[j])))\n",
    "                except:\n",
    "                    dist.append(self.intersampledist(sample1[i],sample2[j]))\n",
    "        return min(dist)\n",
    "\n",
    "\n",
    "    def intersampledist(self,s1,s2):\n",
    "        '''\n",
    "            To be used in case we have one sample and one cluster . It takes the help of one\n",
    "            method 'interclusterdist' to compute the distances between elements of a cluster(which are\n",
    "            samples) and the actual sample given.\n",
    "        '''\n",
    "        if str(type(s2[0]))!='<class \\'list\\'>':\n",
    "            s2=[s2]\n",
    "        if str(type(s1[0]))!='<class \\'list\\'>':\n",
    "            s1=[s1]\n",
    "        m = len(s1)\n",
    "        n = len(s2)\n",
    "        dist = []\n",
    "        if n>=m:\n",
    "            for i in range(n):\n",
    "                for j in range(m):\n",
    "                    if (len(s2[i])>=len(s1[j])) and str(type(s2[i][0])!='<class \\'list\\'>'):\n",
    "                        dist.append(self.interclusterdist(s2[i],s1[j]))\n",
    "                    else:\n",
    "                        dist.append(np.linalg.norm(np.array(s2[i])-np.array(s1[j])))\n",
    "        else:\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    if (len(s1[i])>=len(s2[j])) and str(type(s1[i][0])!='<class \\'list\\'>'):\n",
    "                        dist.append(self.interclusterdist(s1[i],s2[j]))\n",
    "                    else:\n",
    "                        dist.append(np.linalg.norm(np.array(s1[i])-np.array(s2[j])))\n",
    "        return min(dist)\n",
    "\n",
    "    def interclusterdist(self,cl,sample):\n",
    "        if sample[0]!='<class \\'list\\'>':\n",
    "            sample = [sample]\n",
    "        dist   = []\n",
    "        for i in range(len(cl)):\n",
    "            for j in range(len(sample)):\n",
    "                dist.append(np.linalg.norm(np.array(cl[i])-np.array(sample[j])))\n",
    "        return min(dist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "progression = [[i] for i in range(X.shape[0])]\n",
    "samples     = [[list(X[i])] for i in range(X.shape[0])]\n",
    "m = len(samples)\n",
    "distcal  = Distance_computation_grid()\n",
    "\n",
    "while m>1:\n",
    "    print('Sample size before clustering    :- ',m)\n",
    "    Distance_mat      = distcal.compute_distance(samples)\n",
    "    sample_ind_needed = np.where(Distance_mat==Distance_mat.min())[0]\n",
    "    value_to_add      = samples.pop(sample_ind_needed[1])\n",
    "    samples[sample_ind_needed[0]].append(value_to_add)\n",
    "\n",
    "    print('Cluster Node 1                   :-',progression[sample_ind_needed[0]])\n",
    "    print('Cluster Node 2                   :-',progression[sample_ind_needed[1]])\n",
    "\n",
    "    progression[sample_ind_needed[0]].append(progression[sample_ind_needed[1]])\n",
    "    progression[sample_ind_needed[0]] = [progression[sample_ind_needed[0]]]\n",
    "    v = progression.pop(sample_ind_needed[1])\n",
    "    m = len(samples)\n",
    "\n",
    "    print('Progression(Current Sample)      :-',progression)\n",
    "    print('Cluster attained                 :-',progression[sample_ind_needed[0]])\n",
    "    print('Sample size after clustering     :-',m)\n",
    "    print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(X, method = 'ward', metric = 'euclidean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the dendrogram function\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# Create a dendrogram\n",
    "dn = dendrogram(distance_matrix)\n",
    "\n",
    "# Display the dendogram\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
