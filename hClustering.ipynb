{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# PROCESADO DE DATOS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# VISUALIZACION\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ijson\n",
    "import json\n",
    "import random\n",
    "# UNDER SAMPLING\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter\n",
    "\n",
    "import missingno as msno\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "inline_rc = dict(mpl.rcParams)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CARGAMOS LOS DATOS DE yelp_academic_dataset_review.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
      "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
      "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
      "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
      "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0    3.0       0      0     0   \n",
      "1    5.0       1      0     1   \n",
      "2    3.0       0      0     0   \n",
      "3    5.0       1      0     1   \n",
      "4    4.0       1      0     1   \n",
      "\n",
      "                                                text                 date  \n",
      "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n",
      "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n",
      "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n",
      "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
      "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  \n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "with open('data/yelp_academic_dataset_review.json') as fl:\n",
    "    i=0\n",
    "    for review in fl:\n",
    "        reviews.append(json.loads(review))\n",
    "        i+=1\n",
    "        if i + 1 > 10000:\n",
    "            break\n",
    "\n",
    "df_review = pd.DataFrame(reviews)\n",
    "print(df_review.head())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CARGAMOS LOS DATOS DE yelp_academic_dataset_business.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                      name  \\\n",
      "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
      "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
      "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
      "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
      "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
      "\n",
      "                           address           city state postal_code  \\\n",
      "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
      "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
      "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
      "3                      935 Race St   Philadelphia    PA       19107   \n",
      "4                    101 Walnut St     Green Lane    PA       18054   \n",
      "\n",
      "    latitude   longitude  stars  review_count  is_open  \\\n",
      "0  34.426679 -119.711197    5.0             7        0   \n",
      "1  38.551126  -90.335695    3.0            15        1   \n",
      "2  32.223236 -110.880452    3.5            22        0   \n",
      "3  39.955505  -75.155564    4.0            80        1   \n",
      "4  40.338183  -75.471659    4.5            13        1   \n",
      "\n",
      "                                          attributes  \\\n",
      "0                      {'ByAppointmentOnly': 'True'}   \n",
      "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
      "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
      "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
      "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
      "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
      "2  Department Stores, Shopping, Fashion, Home & G...   \n",
      "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
      "4                          Brewpubs, Breweries, Food   \n",
      "\n",
      "                                               hours  \n",
      "0                                               None  \n",
      "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
      "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
      "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
      "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  \n"
     ]
    }
   ],
   "source": [
    "business = []\n",
    "with open('data/yelp_academic_dataset_business.json') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        business.append(json.loads(line))\n",
    "\n",
    "df_business = pd.DataFrame(business)\n",
    "print(df_business.head())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 10000\n",
      "Useful reviews: 4001\n",
      "Funny reviews: 1377\n",
      "Cool reviews: 1964\n",
      "Total negative reviews: 1079\n",
      "Total positive reviews: 7019\n"
     ]
    }
   ],
   "source": [
    "useful_reviews = len(df_review[df_review[\"useful\"]>0])\n",
    "cool_reviews = len(df_review[df_review[\"cool\"]>0])\n",
    "funny_reviews = len(df_review[df_review[\"funny\"]>0])\n",
    "negative_reviws = len(df_review[df_review[\"stars\"]<2])\n",
    "positive_reviews =len(df_review[df_review[\"stars\"]>3])\n",
    "total_reviews = len(df_review)\n",
    "\n",
    "print(\"Total reviews: {}\".format(total_reviews))\n",
    "print(\"Useful reviews: {}\".format(useful_reviews))\n",
    "print(\"Funny reviews: {}\".format(funny_reviews))\n",
    "print(\"Cool reviews: {}\".format(cool_reviews))\n",
    "print(\"Total negative reviews: {}\".format(negative_reviws))\n",
    "print(\"Total positive reviews: {}\".format(positive_reviews))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ELIMINAMOS LAS COLUMNAS INNECESARIAS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_review = df_review.drop([\"review_id\", \"user_id\", \"useful\", \"funny\", \"cool\", \"date\"], axis=1)\n",
    "df_business = df_business.drop([\"name\", \"address\", \"city\", \"state\", \"postal_code\", \"latitude\", \"longitude\", \"stars\", \"review_count\", \"is_open\", \"attributes\", \"hours\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "COMPROBAMOS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id  stars  \\\n",
      "0  XQfwVwDr-v0ZS3_CbbE5Xw    3.0   \n",
      "1  7ATYjTIgM3jUlt4UM3IypQ    5.0   \n",
      "2  YjUWPpI6HXG530lwP-fb2A    3.0   \n",
      "3  kxX2SOes4o-D3ZQBkiMRfA    5.0   \n",
      "4  e4Vwtrqf-wpJfwesgvdgxQ    4.0   \n",
      "\n",
      "                                                text  \n",
      "0  If you decide to eat here, just be aware it is...  \n",
      "1  I've taken a lot of spin classes over the year...  \n",
      "2  Family diner. Had the buffet. Eclectic assortm...  \n",
      "3  Wow!  Yummy, different,  delicious.   Our favo...  \n",
      "4  Cute interior and owner (?) gave us tour of up...  \n",
      "              business_id                                         categories\n",
      "0  Pns2l4eNsfO8kk83dixA6A  Doctors, Traditional Chinese Medicine, Naturop...\n",
      "1  mpf3x-BjTdTEA3yCZrAYPw  Shipping Centers, Local Services, Notaries, Ma...\n",
      "2  tUFrWirKiKi_TAnsVWINQQ  Department Stores, Shopping, Fashion, Home & G...\n",
      "3  MTSW4McQd7CbVtyjqoe9mw  Restaurants, Food, Bubble Tea, Coffee & Tea, B...\n",
      "4  mWMc6_wTdE0EUBKIGXDVfA                          Brewpubs, Breweries, Food\n"
     ]
    }
   ],
   "source": [
    "print(df_review.head())\n",
    "print(df_business.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15619)\t0.2104458399617418\n",
      "  (0, 6192)\t0.10855609151571549\n",
      "  (0, 13782)\t0.08076099116709685\n",
      "  (0, 21438)\t0.1180594895609946\n",
      "  (0, 13680)\t0.04859720545927605\n",
      "  (0, 16371)\t0.07744551748037877\n",
      "  (0, 13771)\t0.068812982404813\n",
      "  (0, 5883)\t0.14191191314453558\n",
      "  (0, 1239)\t0.09584494993848772\n",
      "  (0, 7891)\t0.039774201657384746\n",
      "  (0, 13758)\t0.1978799667774664\n",
      "  (0, 21251)\t0.11570892814183979\n",
      "  (0, 21397)\t0.08697137457813488\n",
      "  (0, 18397)\t0.13848451095725975\n",
      "  (0, 21524)\t0.09891755558593203\n",
      "  (0, 11983)\t0.09493405531570533\n",
      "  (0, 19973)\t0.15421240249770168\n",
      "  (0, 14856)\t0.1284627305556453\n",
      "  (0, 20843)\t0.22486066501780297\n",
      "  (0, 21976)\t0.14533526178170164\n",
      "  (0, 21257)\t0.17080829503104247\n",
      "  (0, 13861)\t0.06155823009612091\n",
      "  (0, 4368)\t0.08012189900768543\n",
      "  (0, 11620)\t0.19381910108012493\n",
      "  (0, 21027)\t0.11652890245654866\n",
      "  :\t:\n",
      "  (9999, 15838)\t0.1276773925983044\n",
      "  (9999, 21625)\t0.06196581503787413\n",
      "  (9999, 1429)\t0.08000467750412457\n",
      "  (9999, 8581)\t0.05835544214372858\n",
      "  (9999, 14793)\t0.046034746199690106\n",
      "  (9999, 21981)\t0.07036017869178077\n",
      "  (9999, 21521)\t0.061747927564766096\n",
      "  (9999, 19724)\t0.04029843941747238\n",
      "  (9999, 3303)\t0.0657885573130496\n",
      "  (9999, 1595)\t0.04987985474903126\n",
      "  (9999, 13909)\t0.07517581822354305\n",
      "  (9999, 13590)\t0.07116143252585333\n",
      "  (9999, 7891)\t0.03595783187076301\n",
      "  (9999, 13861)\t0.05565166353620793\n",
      "  (9999, 3139)\t0.0412522088012075\n",
      "  (9999, 19660)\t0.20547888374500686\n",
      "  (9999, 1178)\t0.05211865613329586\n",
      "  (9999, 21297)\t0.08169424538021257\n",
      "  (9999, 2104)\t0.07011770476482855\n",
      "  (9999, 10384)\t0.17984920175841532\n",
      "  (9999, 10400)\t0.03492451285753466\n",
      "  (9999, 2062)\t0.05133922846429502\n",
      "  (9999, 19900)\t0.12276410360421589\n",
      "  (9999, 21973)\t0.09253969409879337\n",
      "  (9999, 9823)\t0.05548512529181939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "X = []\n",
    "for r in df_review[\"text\"]: #Por cada review\n",
    "    txt = word_tokenize(r.lower()) #Separa la review en palabras\n",
    "    newtxt = \"\"\n",
    "    for w in txt: #Por cada palabra en txt\n",
    "        l = lemma.lemmatize(w) #se hace lo de quitar mayusculas y quitar raice y eso\n",
    "        newtxt += l+\" \"\n",
    "    X.append(newtxt)\n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1      2      3      4      5      6      7      8      9      \\\n",
      "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9995    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9997    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9998    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "      ...  22107  22108  22109  22110  22111  22112  22113  22114  22115  \\\n",
      "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9995  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9996  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9997  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9998  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "9999  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "      22116  \n",
      "0       0.0  \n",
      "1       0.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "...     ...  \n",
      "9995    0.0  \n",
      "9996    0.0  \n",
      "9997    0.0  \n",
      "9998    0.0  \n",
      "9999    0.0  \n",
      "\n",
      "[10000 rows x 22117 columns]\n"
     ]
    }
   ],
   "source": [
    "X= X.toarray()\n",
    "X=pd.DataFrame(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdescribe\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/env3.10/lib/python3.8/site-packages/pandas/core/generic.py:10232\u001B[0m, in \u001B[0;36mNDFrame.describe\u001B[0;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001B[0m\n\u001B[1;32m   9983\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   9984\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdescribe\u001B[39m(\n\u001B[1;32m   9985\u001B[0m     \u001B[38;5;28mself\u001B[39m: NDFrameT,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9989\u001B[0m     datetime_is_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   9990\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NDFrameT:\n\u001B[1;32m   9991\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   9992\u001B[0m \u001B[38;5;124;03m    Generate descriptive statistics.\u001B[39;00m\n\u001B[1;32m   9993\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  10230\u001B[0m \u001B[38;5;124;03m    max            NaN      3.0\u001B[39;00m\n\u001B[1;32m  10231\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m> 10232\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdescribe_ndframe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m  10233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m  10234\u001B[0m \u001B[43m        \u001B[49m\u001B[43minclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m  10235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m  10236\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdatetime_is_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatetime_is_numeric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m  10237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpercentiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpercentiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m  10238\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/env3.10/lib/python3.8/site-packages/pandas/core/describe.py:94\u001B[0m, in \u001B[0;36mdescribe_ndframe\u001B[0;34m(obj, include, exclude, datetime_is_numeric, percentiles)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     87\u001B[0m     describer \u001B[38;5;241m=\u001B[39m DataFrameDescriber(\n\u001B[1;32m     88\u001B[0m         obj\u001B[38;5;241m=\u001B[39mcast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m, obj),\n\u001B[1;32m     89\u001B[0m         include\u001B[38;5;241m=\u001B[39minclude,\n\u001B[1;32m     90\u001B[0m         exclude\u001B[38;5;241m=\u001B[39mexclude,\n\u001B[1;32m     91\u001B[0m         datetime_is_numeric\u001B[38;5;241m=\u001B[39mdatetime_is_numeric,\n\u001B[1;32m     92\u001B[0m     )\n\u001B[0;32m---> 94\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mdescriber\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdescribe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpercentiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpercentiles\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(NDFrameT, result)\n",
      "File \u001B[0;32m~/anaconda3/envs/env3.10/lib/python3.8/site-packages/pandas/core/describe.py:174\u001B[0m, in \u001B[0;36mDataFrameDescriber.describe\u001B[0;34m(self, percentiles)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, series \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    173\u001B[0m     describe_func \u001B[38;5;241m=\u001B[39m select_describe_func(series, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatetime_is_numeric)\n\u001B[0;32m--> 174\u001B[0m     ldesc\u001B[38;5;241m.\u001B[39mappend(\u001B[43mdescribe_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpercentiles\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    176\u001B[0m col_names \u001B[38;5;241m=\u001B[39m reorder_columns(ldesc)\n\u001B[1;32m    177\u001B[0m d \u001B[38;5;241m=\u001B[39m concat(\n\u001B[1;32m    178\u001B[0m     [x\u001B[38;5;241m.\u001B[39mreindex(col_names, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m ldesc],\n\u001B[1;32m    179\u001B[0m     axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    180\u001B[0m     sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    181\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/env3.10/lib/python3.8/site-packages/pandas/core/describe.py:241\u001B[0m, in \u001B[0;36mdescribe_numeric_1d\u001B[0;34m(series, percentiles)\u001B[0m\n\u001B[1;32m    236\u001B[0m formatted_percentiles \u001B[38;5;241m=\u001B[39m format_percentiles(percentiles)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    238\u001B[0m stat_index \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcount\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstd\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m formatted_percentiles \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    239\u001B[0m d \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    240\u001B[0m     [series\u001B[38;5;241m.\u001B[39mcount(), series\u001B[38;5;241m.\u001B[39mmean(), series\u001B[38;5;241m.\u001B[39mstd(), series\u001B[38;5;241m.\u001B[39mmin()]\n\u001B[0;32m--> 241\u001B[0m     \u001B[38;5;241m+\u001B[39m \u001B[43mseries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantile\u001B[49m(percentiles)\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;241m+\u001B[39m [series\u001B[38;5;241m.\u001B[39mmax()]\n\u001B[1;32m    243\u001B[0m )\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Series(d, index\u001B[38;5;241m=\u001B[39mstat_index, name\u001B[38;5;241m=\u001B[39mseries\u001B[38;5;241m.\u001B[39mname)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "X.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seaborn Plot Styling\n",
    "sns.set(style=\"white\", palette=\"husl\")\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# New imports, specific to this example\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "def mai():\n",
    "  D = 2                     # Dimensionality\n",
    "  s = 4                     # Separation so we can control how far apart the means are\n",
    "  mu1 = np.array([0, 0])\n",
    "  mu2 = np.array([s, s])\n",
    "  mu3 = np.array([0, s])\n",
    "\n",
    "  # Call linkage on X, pass in parameter telling what type of linkage to use\n",
    "  Z = linkage(X, 'ward')\n",
    "  # In general, Z will have format index1, index2 for two index's in X that represent the\n",
    "  # points that are joined at that moment. The third column will be the distance, which is\n",
    "  # how far apart the two clusters were before being joined, and the 4th column will be\n",
    "  # sample count, which is the number of points in that cluster. Hence, the size of Z will\n",
    "  # be ((N - 1) x 4)\n",
    "  print(\"Z shape\", Z.shape)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  plt.title(\"Ward\")\n",
    "  dendrogram(Z)      # Call dendrogram on Z\n",
    "  plt.show()\n",
    "\n",
    "  # Now do single linkage for a different example\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  Z = linkage(X, 'single')\n",
    "  plt.title(\"Single\")\n",
    "  dendrogram(Z)\n",
    "  plt.show()\n",
    "\n",
    "  # And one more for complete\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  Z = linkage(X, 'complete')\n",
    "  plt.title(\"Complete\")\n",
    "  dendrogram(Z)\n",
    "  plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mai()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Distance_computation_grid(object):\n",
    "    '''\n",
    "        class to enable the Computation of distance matrix\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compute_distance(self,samples):\n",
    "        '''\n",
    "            Creates a matrix of distances between individual samples and clusters attained at a particular step\n",
    "        '''\n",
    "        Distance_mat = np.zeros((len(samples),len(samples)))\n",
    "        for i in range(Distance_mat.shape[0]):\n",
    "            for j in range(Distance_mat.shape[0]):\n",
    "                if i!=j:\n",
    "                    Distance_mat[i,j] = float(self.distance_calculate(samples[i],samples[j]))\n",
    "                else:\n",
    "                    Distance_mat[i,j] = 10**4\n",
    "        return Distance_mat\n",
    "\n",
    "\n",
    "    def distance_calculate(self,sample1,sample2):\n",
    "        '''\n",
    "            Distance calulated between two samples. The two samples can be both samples, both clusters or\n",
    "            one cluster and one sample. If both of them are samples/clusters, then simple norm is used. In other\n",
    "            cases, we refer it as an exception case and pass the samples as parameter to some function that\n",
    "            calculates the necessary distance between cluster and a sample\n",
    "        '''\n",
    "        dist = []\n",
    "        for i in range(len(sample1)):\n",
    "            for j in range(len(sample2)):\n",
    "                try:\n",
    "                    dist.append(np.linalg.norm(np.array(sample1[i])-np.array(sample2[j])))\n",
    "                except:\n",
    "                    dist.append(self.intersampledist(sample1[i],sample2[j]))\n",
    "        return min(dist)\n",
    "\n",
    "\n",
    "    def intersampledist(self,s1,s2):\n",
    "        '''\n",
    "            To be used in case we have one sample and one cluster . It takes the help of one\n",
    "            method 'interclusterdist' to compute the distances between elements of a cluster(which are\n",
    "            samples) and the actual sample given.\n",
    "        '''\n",
    "        if str(type(s2[0]))!='<class \\'list\\'>':\n",
    "            s2=[s2]\n",
    "        if str(type(s1[0]))!='<class \\'list\\'>':\n",
    "            s1=[s1]\n",
    "        m = len(s1)\n",
    "        n = len(s2)\n",
    "        dist = []\n",
    "        if n>=m:\n",
    "            for i in range(n):\n",
    "                for j in range(m):\n",
    "                    if (len(s2[i])>=len(s1[j])) and str(type(s2[i][0])!='<class \\'list\\'>'):\n",
    "                        dist.append(self.interclusterdist(s2[i],s1[j]))\n",
    "                    else:\n",
    "                        dist.append(np.linalg.norm(np.array(s2[i])-np.array(s1[j])))\n",
    "        else:\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    if (len(s1[i])>=len(s2[j])) and str(type(s1[i][0])!='<class \\'list\\'>'):\n",
    "                        dist.append(self.interclusterdist(s1[i],s2[j]))\n",
    "                    else:\n",
    "                        dist.append(np.linalg.norm(np.array(s1[i])-np.array(s2[j])))\n",
    "        return min(dist)\n",
    "\n",
    "    def interclusterdist(self,cl,sample):\n",
    "        if sample[0]!='<class \\'list\\'>':\n",
    "            sample = [sample]\n",
    "        dist   = []\n",
    "        for i in range(len(cl)):\n",
    "            for j in range(len(sample)):\n",
    "                dist.append(np.linalg.norm(np.array(cl[i])-np.array(sample[j])))\n",
    "        return min(dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "progression = [[i] for i in range(X.shape[0])]\n",
    "samples     = [[list(X[i])] for i in range(X.shape[0])]\n",
    "m = len(samples)\n",
    "distcal  = Distance_computation_grid()\n",
    "\n",
    "while m>1:\n",
    "    print('Sample size before clustering    :- ',m)\n",
    "    Distance_mat      = distcal.compute_distance(samples)\n",
    "    sample_ind_needed = np.where(Distance_mat==Distance_mat.min())[0]\n",
    "    value_to_add      = samples.pop(sample_ind_needed[1])\n",
    "    samples[sample_ind_needed[0]].append(value_to_add)\n",
    "\n",
    "    print('Cluster Node 1                   :-',progression[sample_ind_needed[0]])\n",
    "    print('Cluster Node 2                   :-',progression[sample_ind_needed[1]])\n",
    "\n",
    "    progression[sample_ind_needed[0]].append(progression[sample_ind_needed[1]])\n",
    "    progression[sample_ind_needed[0]] = [progression[sample_ind_needed[0]]]\n",
    "    v = progression.pop(sample_ind_needed[1])\n",
    "    m = len(samples)\n",
    "\n",
    "    print('Progression(Current Sample)      :-',progression)\n",
    "    print('Cluster attained                 :-',progression[sample_ind_needed[0]])\n",
    "    print('Sample size after clustering     :-',m)\n",
    "    print('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(X, method = 'ward', metric = 'euclidean')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the dendrogram function\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# Create a dendrogram\n",
    "dn = dendrogram(distance_matrix)\n",
    "\n",
    "# Display the dendogram\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
